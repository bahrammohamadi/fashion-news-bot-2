import os
import asyncio
import feedparser
from datetime import datetime, timedelta, timezone
from telegram import Bot, LinkPreviewOptions
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.exception import AppwriteException
from appwrite.query import Query
from openai import AsyncOpenAI
import random

async def main(event=None, context=None):
    print("[INFO] Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ main Ø´Ø±ÙˆØ¹ Ø´Ø¯")

    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHANNEL_ID')
    appwrite_endpoint = os.environ.get('APPWRITE_ENDPOINT', 'https://fra.cloud.appwrite.io/v1')
    appwrite_project = os.environ.get('APPWRITE_PROJECT_ID')
    appwrite_key = os.environ.get('APPWRITE_API_KEY')
    database_id = os.environ.get('APPWRITE_DATABASE_ID')
    collection_id = 'history'

    if not all([token, chat_id, appwrite_project, appwrite_key, database_id]):
        print("[ERROR] Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ù†Ø§Ù‚Øµ!")
        return {"status": "error"}

    bot = Bot(token=token)

    aw_client = Client()
    aw_client.set_endpoint(appwrite_endpoint)
    aw_client.set_project(appwrite_project)
    aw_client.set_key(appwrite_key)
    databases = Databases(aw_client)

    openrouter_client = AsyncOpenAI(
        api_key=os.environ.get('OPENROUTER_API_KEY'),
        base_url="https://openrouter.ai/api/v1"
    )

    rss_feeds = [
        "https://www.vogue.com/feed/rss",
        "https://wwd.com/feed/",
        "https://fashionista.com/feed",
        "https://www.harpersbazaar.com/rss/fashion.xml",
        "https://www.elle.com/rss/fashion.xml",
        "https://www.businessoffashion.com/feed/",
        "https://www.thecut.com/feed",
        "https://www.refinery29.com/rss.xml",
        "https://www.whowhatwear.com/rss",
        "https://feeds.feedburner.com/fibre2fashion/fashion-news",
        "https://www.gq.com/feed/style/rss",
        "https://www.cosmopolitan.com/rss/fashion.xml",
        "https://www.instyle.com/rss/fashion.xml",
        "https://www.marieclaire.com/rss/fashion.xml",
        "https://www.vanityfair.com/feed/style/rss",
        "https://www.allure.com/feed/fashion/rss",
        "https://www.teenvogue.com/feed/rss",
        "https://www.glossy.co/feed/",
        "https://www.highsnobiety.com/feed/",
        "https://fashionmagazine.com/feed/",
    ]

    now = datetime.now(timezone.utc)
    time_threshold = now - timedelta(hours=24)

    posted = False

    for feed_url in rss_feeds:
        if posted:
            break

        try:
            feed = feedparser.parse(feed_url)
            if not feed.entries:
                print(f"[INFO] ÙÛŒØ¯ Ø®Ø§Ù„ÛŒ: {feed_url}")
                continue

            for entry in feed.entries:
                if posted:
                    break

                published = entry.get('published_parsed') or entry.get('updated_parsed')
                if not published:
                    continue
                pub_date = datetime(*published[:6], tzinfo=timezone.utc)
                if pub_date < time_threshold:
                    continue

                title = entry.title.strip()
                link = entry.link.strip()
                description = (entry.get('summary') or entry.get('description') or '').strip()
                content_raw = description[:800]

                try:
                    existing = databases.list_documents(
                        database_id=database_id,
                        collection_id=collection_id,
                        queries=[Query.equal("link", link)]
                    )
                    if existing['total'] > 0:
                        print(f"[INFO] ØªÚ©Ø±Ø§Ø±ÛŒ Ø±Ø¯ Ø´Ø¯: {title[:60]}")
                        continue
                except Exception as db_err:
                    print(f"[WARN] Ø®Ø·Ø§ Ø¯Ø± Ú†Ú© Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ú†Ú©): {str(db_err)}")

                # Ù¾Ø±Ø§Ù…Ù¾Øª Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡: Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ù„ÛŒØ¨Ù„ ÛŒØ§ Ù…Ù‚Ø¯Ù…Ù‡ Ø§Ø¶Ø§ÙÛŒ
                prompt = f"""You are a senior Persian fashion editor writing for a professional fashion publication.

Write a magazine-quality Persian fashion news article.

Input:
Title: {title}
Summary: {description}
Content: {content_raw}
Source URL: {feed_url}
Publish Date: {pub_date.strftime('%Y-%m-%d')}

Instructions:
1. Detect language: Translate English to fluent Persian. Keep Persian as is.
2. Do NOT translate proper nouns (brands, designers, locations, events).
3. Structure naturally â€“ do NOT use ANY section labels, headers, or extra text like "Headline:", "Lead:", "Body:", "Industry Perspective:", "Ù…Ù‚Ø§Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ" or anything similar.
4. Start DIRECTLY with a strong headline (8â€“14 words) on the first line.
5. Follow immediately with lead paragraph (1â€“2 sentences).
6. Then write 2â€“4 body paragraphs with logical flow.
7. End with 2â€“3 sentences neutral industry analysis (impact on market/designers/consumers).
8. Tone: formal, engaging, journalistic.
9. Length: 220â€“350 words.
10. Use only input information â€“ no speculation or added facts.

Output ONLY the clean Persian article text (no extra labels, no introduction, no "##", no "Ù…Ù‚Ø§Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ"):
[ØªÛŒØªØ± Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ]

[Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù Ù„ÛŒØ¯]

[Ø¨Ø¯Ù†Ù‡ Ø®Ø¨Ø±]

[Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡]
"""

                content = await translate_with_openrouter(openrouter_client, prompt)

                # ÙØ±Ù…Øª Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø³Øª: ØªØµÙˆÛŒØ± + ØªÛŒØªØ± ÙØ§Ø±Ø³ÛŒ + Ù…ØªÙ† Ø®Ø¨Ø± + Ø§Ù†ØªÙ‡Ø§ Ù„ÛŒÙ†Ú© Ú©Ø§Ù†Ø§Ù„ Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹ (Ø¨Ø¯ÙˆÙ† Ù„ÛŒÙ†Ú© Ø®Ø¨Ø±)
                final_text = f"{content}\n\n@irfashionnews - Ù…Ø¯ Ùˆ ÙØ´Ù† Ø§ÛŒØ±Ø§Ù†ÛŒ"

                try:
                    image_url = get_image_from_rss(entry)
                    if image_url:
                        await bot.send_photo(
                            chat_id=chat_id,
                            photo=image_url,
                            caption=final_text,
                            parse_mode='HTML',
                            disable_notification=True
                        )
                    else:
                        await bot.send_message(
                            chat_id=chat_id,
                            text=final_text,
                            link_preview_options=LinkPreviewOptions(is_disabled=True),
                            disable_notification=True
                        )

                    posted = True
                    print(f"[SUCCESS] Ù¾Ø³Øª Ù…ÙˆÙÙ‚ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {title[:60]}")

                    # Ø§Ø±Ø³Ø§Ù„ Û´ Ø§Ø³ØªÛŒÚ©Ø± Ø±Ù†Ø¯ÙˆÙ… ÙˆØ§Ú©Ù†Ø´ Ø¨Ø§ emoji Ø¹Ù…ÙˆÙ…ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
                    reaction_emojis = [
                        "ğŸ‘", "ğŸ”¥", "ğŸŒ¹", "â¤ï¸", "âœ¨",
                        "ğŸ˜", "ğŸ‘", "ğŸŒŸ", "ğŸ’ƒ", "ğŸ‘—",
                        "ğŸ‘ ", "ğŸ‘œ", "ğŸ€", "ğŸ’…", "ğŸ¥°"
                    ]
                    selected_emojis = random.sample(reaction_emojis, k=4)
                    for emoji in selected_emojis:
                        try:
                            await bot.send_sticker(
                                chat_id=chat_id,
                                sticker=emoji,
                                disable_notification=True
                            )
                        except Exception as sticker_err:
                            print(f"[WARN] Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø§Ø³ØªÛŒÚ©Ø±: {str(sticker_err)}")
                    print("[INFO] Û´ Ø§Ø³ØªÛŒÚ©Ø± ÙˆØ§Ú©Ù†Ø´ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")

                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                    try:
                        databases.create_document(
                            database_id=database_id,
                            collection_id=collection_id,
                            document_id='unique()',
                            data={
                                'link': link,
                                'title': title,
                                'published_at': now.isoformat(),
                                'feed_url': feed_url,
                                'created_at': now.isoformat()
                            }
                        )
                        print("[SUCCESS] Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆÙÙ‚")
                    except Exception as save_err:
                        print(f"[WARN] Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {str(save_err)}")

                except Exception as send_err:
                    print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª: {str(send_err)}")

        except Exception as feed_err:
            print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙÛŒØ¯ {feed_url}: {str(feed_err)}")

    print(f"[INFO] Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ - Ù¾Ø³Øª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {posted}")
    return {"status": "success", "posted": posted}


async def translate_with_openrouter(client, prompt):
    try:
        response = await client.chat.completions.create(
            model="deepseek/deepseek-r1-0528:free",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
            max_tokens=900
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ Ø¨Ø§ DeepSeek R1: {str(e)}")
        return "(ØªØ±Ø¬Ù…Ù‡ Ù…ÙˆÙ‚Øª - Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯)"


def get_image_from_rss(entry):
    if 'enclosure' in entry and entry.enclosure.get('type', '').startswith('image/'):
        return entry.enclosure.href
    if 'media_content' in entry:
        for media in entry.media_content:
            if media.get('medium') == 'image' and media.get('url'):
                return media.get('url')
    return None


if __name__ == "__main__":
    asyncio.run(main())