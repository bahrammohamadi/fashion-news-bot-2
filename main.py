import os
import asyncio
import feedparser
import requests
from datetime import datetime, timedelta, timezone
from telegram import Bot
from bs4 import BeautifulSoup
from openai import AsyncOpenAI
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.exception import AppwriteException
from appwrite.query import Query

async def main(event=None, context=None):
    print("[INFO] Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ main Ø´Ø±ÙˆØ¹ Ø´Ø¯")

    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHANNEL_ID')
    gapgpt_key = os.environ.get('GAPGPT_API_KEY')
    appwrite_endpoint = os.environ.get('APPWRITE_ENDPOINT', 'https://cloud.appwrite.io/v1')
    appwrite_project = os.environ.get('APPWRITE_PROJECT_ID')
    appwrite_key = os.environ.get('APPWRITE_API_KEY')
    database_id = os.environ.get('APPWRITE_DATABASE_ID')
    collection_id = 'history'

    if not all([token, chat_id, gapgpt_key, appwrite_project, appwrite_key, database_id]):
        print("[ERROR] Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ù†Ø§Ù‚Øµ!")
        return {"status": "error"}

    bot = Bot(token=token)

    client = AsyncOpenAI(
        api_key=gapgpt_key,
        base_url="https://api.gapgpt.app/v1"
    )

    aw_client = Client()
    aw_client.set_endpoint(appwrite_endpoint)
    aw_client.set_project(appwrite_project)
    aw_client.set_key(appwrite_key)
    databases = Databases(aw_client)

    rss_feeds = [
        "https://medopia.ir/feed/",
        "https://www.digistyle.com/mag/feed/",
        "https://www.chibepoosham.com/feed/",
        "https://www.tarahanelebas.com/feed/",
        "https://www.persianpood.com/feed/",
        "https://www.jument.style/feed/",
        "https://www.zibamoon.com/feed/",
        "https://www.sarak-co.com/feed/",
        "https://www.elsana.com/feed/",
        "https://www.beytoote.com/rss/fashion",
        "https://www.namnak.com/rss/fashion",
        "https://www.modetstyle.com/feed/",
        "https://www.antikstyle.com/feed/",
        "https://www.rnsfashion.com/feed/",
        "https://www.pattonjameh.com/feed/",
        "https://www.tonikaco.com/feed/",
        "https://www.zoomit.ir/feed/category/fashion-beauty/",
        "https://www.khabaronline.ir/rss/category/Ù…Ø¯-Ø²ÛŒØ¨Ø§ÛŒÛŒ",
        "https://fararu.com/rss/category/Ù…Ø¯-Ø²ÛŒØ¨Ø§ÛŒÛŒ",
        "https://www.digikala.com/mag/feed/?category=Ù…Ø¯-Ùˆ-Ø²ÛŒØ¨Ø§ÛŒÛŒ",
    ]

    now = datetime.now(timezone.utc)
    time_threshold = now - timedelta(days=4)

    posted_count = 0
    max_posts_per_run = 1  # ÙÙ‚Ø· Û± Ù¾Ø³Øª Ø¯Ø± Ù‡Ø± Ø§Ø¬Ø±Ø§

    for feed_url in rss_feeds:
        if posted_count >= max_posts_per_run:
            break

        try:
            feed = feedparser.parse(feed_url)
            if not feed.entries:
                continue

            for entry in feed.entries:
                if posted_count >= max_posts_per_run:
                    break

                published = entry.get('published_parsed') or entry.get('updated_parsed')
                if not published:
                    continue
                pub_date = datetime(*published[:6], tzinfo=timezone.utc)
                if pub_date < time_threshold:
                    continue

                title = entry.title.strip()
                link = entry.link.strip()
                raw_html = entry.get('summary') or entry.get('description') or ''

                soup = BeautifulSoup(raw_html, 'html.parser')
                content_raw = soup.get_text(separator=' ').strip()

                # ÙÛŒÙ„ØªØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ GapGPT
                is_fashion = await is_fashion_related(client, title, content_raw)
                if not is_fashion:
                    print(f"[FILTER] Ø±Ø¯ Ø´Ø¯ (ØºÛŒØ±Ù…Ø±ØªØ¨Ø·): {title[:60]}")
                    continue

                # ØªØ±Ø¬Ù…Ù‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡ ÙØ´Ù†
                final_content = await process_fashion_article(client, title, content_raw, link, pub_date)

                final_text = f"{final_content}\n\nğŸ”— {link}"

                image_url = get_image_from_rss(entry)
                if not image_url:
                    image_url = await extract_image_from_page(link)

                try:
                    if image_url:
                        await bot.send_photo(
                            chat_id=chat_id,
                            photo=image_url,
                            caption=final_text,
                            parse_mode='HTML',
                            disable_notification=True
                        )
                    else:
                        await bot.send_message(
                            chat_id=chat_id,
                            text=final_text,
                            disable_web_page_preview=True,
                            disable_notification=True
                        )

                    posted_count += 1
                    print(f"[SUCCESS] Ù¾Ø³Øª Ù…ÙˆÙÙ‚: {title[:60]}")

                    try:
                        databases.create_document(
                            database_id=database_id,
                            collection_id=collection_id,
                            document_id='unique()',
                            data={
                                'link': link,
                                'title': title,
                                'published_at': now.isoformat(),
                                'feed_url': feed_url
                            }
                        )
                    except Exception as save_err:
                        print(f"[WARN] Ø®Ø·Ø§ Ø°Ø®ÛŒØ±Ù‡ DB: {str(save_err)}")

                except Exception as send_err:
                    print(f"[ERROR] Ø®Ø·Ø§ Ø§Ø±Ø³Ø§Ù„: {str(send_err)}")

        except Exception as feed_err:
            print(f"[ERROR] Ø®Ø·Ø§ ÙÛŒØ¯ {feed_url}: {str(feed_err)}")

    print(f"[INFO] Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø³Øª Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {posted_count}")
    return {"status": "success", "posted": posted_count}


async def is_fashion_related(client, title, content_raw):
    prompt = f"""ÙÙ‚Ø· Ø¨Ø§ "Ø¨Ù„Ù‡" ÛŒØ§ "Ø®ÛŒØ±" Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡.

Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø®Ø¨Ø± Ø¯Ø± Ø­ÙˆØ²Ù‡ Ù…Ø¯ØŒ ÙØ´Ù†ØŒ Ø§Ø³ØªØ§ÛŒÙ„ØŒ Ø²ÛŒØ¨Ø§ÛŒÛŒØŒ Ù„Ø¨Ø§Ø³ØŒ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ù¾ÙˆØ´Ø§Ú©ØŒ Ø·Ø±Ø§Ø­ÛŒ Ù„Ø¨Ø§Ø³ ÛŒØ§ Ø§Ø³ØªØ§ÛŒÙ„ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ø³ØªØŸ

Ø¹Ù†ÙˆØ§Ù†: {title}
Ù…ØªÙ†: {content_raw[:500]}

Ø¬ÙˆØ§Ø¨ ÙÙ‚Ø·: Ø¨Ù„Ù‡ ÛŒØ§ Ø®ÛŒØ±"""

    try:
        response = await client.chat.completions.create(
            model="gemini-2.5-pro",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0.0
        )
        answer = response.choices[0].message.content.strip().lower()
        return "Ø¨Ù„Ù‡" in answer
    except Exception as e:
        print(f"[WARN] Ø®Ø·Ø§ ÙÛŒÙ„ØªØ±: {str(e)}")
        return False


async def process_fashion_article(client, title, content_raw, link, pub_date):
    translate_prompt = f"""
ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…ØªÙ† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø²ÛŒØ± Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ùˆ Ù…Ù†Ø§Ø³Ø¨ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ù…Ø¯:

Ù…ØªÙ†:
{content_raw[:1200]}

Ø®Ø±ÙˆØ¬ÛŒ ÙÙ‚Ø· ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ù‡ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÛŒ.
"""

    try:
        translate_res = await client.chat.completions.create(
            model="gemini-2.5-pro",
            messages=[{"role": "user", "content": translate_prompt}],
            max_tokens=1200,
            temperature=0.3
        )
        translated = translate_res.choices[0].message.content.strip()
    except:
        translated = content_raw[:800] + "..."

    fashion_prompt = f"""
Ø´Ù…Ø§ ÙˆÛŒØ±Ø§Ø³ØªØ§Ø± Ø§Ø±Ø´Ø¯ Ø®Ø¨Ø± Ù…Ø¯ Ù‡Ø³ØªÛŒØ¯. Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ù¾Ø³Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ù…Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯.

Ø¹Ù†ÙˆØ§Ù†: {title}
Ù…ØªÙ† ØªØ±Ø¬Ù…Ù‡â€ŒØ´Ø¯Ù‡: {translated}
Ù„ÛŒÙ†Ú© Ù…Ù†Ø¨Ø¹: {link}
ØªØ§Ø±ÛŒØ® Ø§Ù†ØªØ´Ø§Ø±: {pub_date.strftime('%Y-%m-%d')}

Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø³Øª:
- ØªÛŒØªØ± Ø¬Ø°Ø§Ø¨ (Û¸â€“Û±Û´ Ú©Ù„Ù…Ù‡)
- Ù…ØªÙ† Ø§ØµÙ„ÛŒ (Û²Û°Û°â€“Û´Û°Û° Ú©Ù„Ù…Ù‡ØŒ Ø±ÙˆØ§Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)
- ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Û²â€“Û³ Ø¬Ù…Ù„Ù‡ (Ø¯Ø±Ø¨Ø§Ø±Ù‡ ØªØ£Ø«ÛŒØ± Ø¯Ø± Ø¨Ø§Ø²Ø§Ø± Ù…Ø¯ ÛŒØ§ Ø§Ø³ØªØ§ÛŒÙ„ Ø§ÛŒØ±Ø§Ù†ÛŒ)
- Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§

Ø®Ø±ÙˆØ¬ÛŒ ÙÙ‚Ø· Ù¾Ø³Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§Ø´Ù‡ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÛŒ.
"""

    try:
        fashion_res = await client.chat.completions.create(
            model="gemini-2.5-pro",
            messages=[{"role": "user", "content": fashion_prompt}],
            max_tokens=1500,
            temperature=0.4
        )
        return fashion_res.choices[0].message.content.strip()
    except:
        return f"**{title}**\n\n{translated[:800]}...\n\nÙ…Ù†Ø¨Ø¹: {link}"


def get_image_from_rss(entry):
    if 'enclosure' in entry and entry.enclosure.get('type', '').startswith('image/'):
        return entry.enclosure.href
    if 'media_content' in entry:
        for media in entry.media_content:
            if media.get('medium') == 'image' and media.get('url'):
                return media.get('url')
    return None


async def extract_image_from_page(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, timeout=8, headers=headers)
        if response.status_code != 200:
            return None

        soup = BeautifulSoup(response.text, 'html.parser')
        og = soup.find('meta', property='og:image')
        if og and og.get('content'):
            return og['content']

        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src')
            if src and len(src) > 15:
                if any(bad in src.lower() for bad in ['logo', 'icon', 'banner']):
                    continue
                return src
        return None
    except:
        return None


if __name__ == "__main__":
    asyncio.run(main())
