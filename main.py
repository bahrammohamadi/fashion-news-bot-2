import os
import asyncio
import feedparser
import requests
from datetime import datetime, timedelta, timezone
from telegram import Bot
from bs4 import BeautifulSoup
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.exception import AppwriteException
from appwrite.query import Query

async def main(event=None, context=None):
    print("[INFO] Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ main Ø´Ø±ÙˆØ¹ Ø´Ø¯")

    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHANNEL_ID')
    appwrite_endpoint = os.environ.get('APPWRITE_ENDPOINT', 'https://cloud.appwrite.io/v1')
    appwrite_project = os.environ.get('APPWRITE_PROJECT_ID')
    appwrite_key = os.environ.get('APPWRITE_API_KEY')
    database_id = os.environ.get('APPWRITE_DATABASE_ID')
    collection_id = 'history'

    if not all([token, chat_id, appwrite_project, appwrite_key, database_id]):
        print("[ERROR] Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ù†Ø§Ù‚Øµ!")
        return {"status": "error"}

    bot = Bot(token=token)

    aw_client = Client()
    aw_client.set_endpoint(appwrite_endpoint)
    aw_client.set_project(appwrite_project)
    aw_client.set_key(appwrite_key)
    databases = Databases(aw_client)

    rss_feeds = [
        "https://www.vogue.com/feed/rss",
        "https://wwd.com/feed/",
        "https://www.harpersbazaar.com/rss/fashion.xml",
        "https://fashionista.com/feed",
        "https://www.businessoffashion.com/feed/",
        "https://www.elle.com/rss/fashion.xml",
        "https://www.refinery29.com/rss.xml",
        "https://www.thecut.com/feed",
        "https://www.whowhatwear.com/rss",
        "https://www.instyle.com/rss",
        "https://www.marieclaire.com/rss/fashion/",
        "https://www.glamour.com/rss/fashion",
        "https://www.allure.com/rss",
        "https://nylon.com/feed",
        "https://www.papermag.com/rss",
        "https://www.highsnobiety.com/feed/",
        "https://hypebeast.com/feed",
        "https://www.ssense.com/en-us/editorial/rss",
        "https://www.dazeddigital.com/rss",
        "https://i-d.vice.com/en/rss",
    ]

    now = datetime.now(timezone.utc)
    time_threshold = now - timedelta(days=1)   # Û²Û´ Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ±

    posted_count = 0
    max_posts_per_run = 4   # Ø­Ø¯Ø§Ú©Ø«Ø± Û´ Ù¾Ø³Øª Ø¯Ø± Ù‡Ø± Ø§Ø¬Ø±Ø§

    for feed_url in rss_feeds:
        if posted_count >= max_posts_per_run:
            break

        try:
            feed = feedparser.parse(feed_url)
            if not feed.entries:
                continue

            for entry in feed.entries:
                if posted_count >= max_posts_per_run:
                    break

                published = entry.get('published_parsed') or entry.get('updated_parsed')
                if not published:
                    continue
                pub_date = datetime(*published[:6], tzinfo=timezone.utc)
                if pub_date < time_threshold:
                    continue

                title = entry.title.strip()
                link = entry.link.strip()
                raw_html = entry.get('summary') or entry.get('description') or ''
                soup = BeautifulSoup(raw_html, 'html.parser')
                content_raw = soup.get_text(separator=' ').strip()

                # Ù…Ø±Ø­Ù„Ù‡ Û±: ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§ Ù¾Ø±Ø§Ù…Ù¾Øª Ø«Ø§Ø¨Øª
                translated = translate_to_persian(title, content_raw)

                # Ù…Ø±Ø­Ù„Ù‡ Û²: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡ ÙØ´Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¯ÙˆÙ…
                final_content = convert_to_fashion_article(translated, title, link, pub_date)

                final_text = f"{final_content}\n\nğŸ”— {link}"

                try:
                    image_url = get_image_from_rss(entry)
                    if image_url:
                        await bot.send_photo(chat_id=chat_id, photo=image_url, caption=final_text, parse_mode='HTML', disable_notification=True)
                    else:
                        await bot.send_message(chat_id=chat_id, text=final_text, disable_web_page_preview=True, disable_notification=True)

                    posted_count += 1
                    print(f"[SUCCESS] Ù¾Ø³Øª Ù…ÙˆÙÙ‚: {title[:60]}")

                    try:
                        databases.create_document(
                            database_id=database_id,
                            collection_id=collection_id,
                            document_id='unique()',
                            data={
                                'link': link,
                                'title': title,
                                'published_at': now.isoformat(),
                                'feed_url': feed_url
                            }
                        )
                    except Exception as save_err:
                        print(f"[WARN] Ø®Ø·Ø§ Ø°Ø®ÛŒØ±Ù‡ DB: {str(save_err)}")

                except Exception as send_err:
                    print(f"[ERROR] Ø®Ø·Ø§ Ø§Ø±Ø³Ø§Ù„: {str(send_err)}")

        except Exception as feed_err:
            print(f"[ERROR] Ø®Ø·Ø§ ÙÛŒØ¯ {feed_url}: {str(feed_err)}")

    print(f"[INFO] Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø³Øª Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {posted_count}")
    return {"status": "success", "posted": posted_count}


def translate_to_persian(title, content_raw):
    """Ù¾Ø±Ø§Ù…Ù¾Øª Ø«Ø§Ø¨Øª ØªØ±Ø¬Ù…Ù‡ Ø¯Ù‚ÛŒÙ‚"""
    # Ø§ÛŒÙ†Ø¬Ø§ ÙÙ‚Ø· ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ùˆ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªØ±Ø¬Ù…Ù‡ (Ú†ÙˆÙ† Ø¨Ø¯ÙˆÙ† LLM ÙˆØ§Ù‚Ø¹ÛŒ Ù‡Ø³ØªÛŒÙ…)
    return f"{title}\n\n{content_raw[:450]}..."


def convert_to_fashion_article(translated, title, link, pub_date):
    """Ù¾Ø±Ø§Ù…Ù¾Øª Ø¯ÙˆÙ… - ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡ ÙØ´Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    return f"""**{title}**

{translated}

Ø§ÛŒÙ† ØªØ±Ù†Ø¯ ÛŒØ§ Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²Ø´Ù…Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ§ÛŒÙ„ Ø±ÙˆØ²Ù…Ø±Ù‡ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ø¯Ø± ÙØµÙ„ Ø¬Ø§Ø±ÛŒ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.

#Ù…Ø¯ #Ø§Ø³ØªØ§ÛŒÙ„ #ØªØ±Ù†Ø¯ #ÙØ´Ù†_Ø§ÛŒØ±Ø§Ù†ÛŒ #Ù…Ù‡Ø±Ø¬Ø§Ù…Ù‡"""


def get_image_from_rss(entry):
    if 'enclosure' in entry and entry.enclosure.get('type', '').startswith('image/'):
        return entry.enclosure.href
    if 'media_content' in entry:
        for media in entry.media_content:
            if media.get('medium') == 'image' and media.get('url'):
                return media.get('url')
    return None


if __name__ == "__main__":
    asyncio.run(main())
