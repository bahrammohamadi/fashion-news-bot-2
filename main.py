import os
import asyncio
import feedparser
from datetime import datetime, timedelta, timezone
from telegram import Bot, LinkPreviewOptions
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.exception import AppwriteException
from appwrite.query import Query
from openai import AsyncOpenAI

async def main(event=None, context=None):
    print("[INFO] Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ main Ø´Ø±ÙˆØ¹ Ø´Ø¯")

    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
    token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHANNEL_ID')
    appwrite_endpoint = os.environ.get('APPWRITE_ENDPOINT', 'https://fra.cloud.appwrite.io/v1')
    appwrite_project = os.environ.get('APPWRITE_PROJECT_ID')
    appwrite_key = os.environ.get('APPWRITE_API_KEY')
    database_id = os.environ.get('APPWRITE_DATABASE_ID')
    collection_id = 'history'

    # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
    if not all([token, chat_id, appwrite_project, appwrite_key, database_id]):
        print("[ERROR] Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ù†Ø§Ù‚Øµ! APPWRITE_PROJECT_ID Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯.")
        return {"status": "error"}

    bot = Bot(token=token)

    aw_client = Client()
    aw_client.set_endpoint(appwrite_endpoint)
    aw_client.set_project(appwrite_project)
    aw_client.set_key(appwrite_key)
    databases = Databases(aw_client)

    openrouter_client = AsyncOpenAI(
        api_key=os.environ.get('OPENROUTER_API_KEY'),
        base_url="https://openrouter.ai/api/v1"
    )

    # Ù„ÛŒØ³Øª 20 ÙÛŒØ¯ Ø®Ø§Ø±Ø¬ÛŒ Ù…Ø¯ Ùˆ ÙØ´Ù†
    rss_feeds = [
        "https://www.vogue.com/feed/rss",
        "https://wwd.com/feed/",
        "https://fashionista.com/feed",
        "https://www.harpersbazaar.com/rss/fashion.xml",
        "https://www.elle.com/rss/fashion.xml",
        "https://www.businessoffashion.com/feed/",
        "https://www.thecut.com/feed",
        "https://www.refinery29.com/rss.xml",
        "https://www.whowhatwear.com/rss",
        "https://feeds.feedburner.com/fibre2fashion/fashion-news",
        "https://www.gq.com/feed/style/rss",
        "https://www.cosmopolitan.com/rss/fashion.xml",
        "https://www.instyle.com/rss/fashion.xml",
        "https://www.marieclaire.com/rss/fashion.xml",
        "https://www.vanityfair.com/feed/style/rss",
        "https://www.allure.com/feed/fashion/rss",
        "https://www.teenvogue.com/feed/rss",
        "https://www.glossy.co/feed/",
        "https://www.highsnobiety.com/feed/",
        "https://fashionmagazine.com/feed/",
    ]

    now = datetime.now(timezone.utc)
    time_threshold = now - timedelta(hours=24)

    posted = False

    for feed_url in rss_feeds:
        if posted:
            break

        try:
            feed = feedparser.parse(feed_url)
            if not feed.entries:
                print(f"[INFO] ÙÛŒØ¯ Ø®Ø§Ù„ÛŒ: {feed_url}")
                continue

            is_persian = any(x in feed_url.lower() for x in ['.ir', 'khabaronline', 'medopia'])

            for entry in feed.entries:
                if posted:
                    break

                published = entry.get('published_parsed') or entry.get('updated_parsed')
                if not published:
                    continue
                pub_date = datetime(*published[:6], tzinfo=timezone.utc)
                if pub_date < time_threshold:
                    continue

                title = entry.title.strip()
                link = entry.link.strip()
                description = (entry.get('summary') or entry.get('description') or '').strip()
                content_raw = description[:800]

                # Ú†Ú© ØªÚ©Ø±Ø§Ø±ÛŒ
                try:
                    existing = databases.list_documents(
                        database_id=database_id,
                        collection_id=collection_id,
                        queries=[Query.equal("link", link)]
                    )
                    if existing['total'] > 0:
                        print(f"[INFO] ØªÚ©Ø±Ø§Ø±ÛŒ Ø±Ø¯ Ø´Ø¯: {title[:60]}")
                        continue
                except Exception as db_err:
                    print(f"[WARN] Ø®Ø·Ø§ Ø¯Ø± Ú†Ú© Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ú†Ú©): {str(db_err)}")

                # Ù¾Ø±Ø§Ù…Ù¾Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
                prompt = f"""You are a senior Persian fashion editor writing for a professional fashion publication.

Write a magazine-quality Persian fashion news article.

Input:
Title: {title}
Summary: {description}
Content: {content_raw}
Source URL: {feed_url}
Publish Date: {pub_date.strftime('%Y-%m-%d')}

Instructions:
1. Detect language: Translate English to fluent Persian. Keep Persian as is.
2. Do NOT translate proper nouns.
3. Structure naturally (no labels).
4. Headline: 8â€“14 words.
5. Lead: 1â€“2 sentences.
6. Body: 2â€“4 paragraphs.
7. End with 2â€“3 sentences industry analysis (neutral, objective).
8. Tone: formal, journalistic.
9. Length: 220â€“350 words.
10. Use only input information.

Output:
[ØªÛŒØªØ± ÙØ§Ø±Ø³ÛŒ]

[Ù„ÛŒØ¯]

[Ø¨Ø¯Ù†Ù‡]

[ØªØ­Ù„ÛŒÙ„]

Ù…Ù†Ø¨Ø¹: {feed_url}
"""

                content = await translate_with_openrouter(openrouter_client, prompt)

                # ÙØ±Ù…Øª Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø³Øª: ØªØµÙˆÛŒØ± + ØªÛŒØªØ± ÙØ§Ø±Ø³ÛŒ + Ù…ØªÙ† Ø®Ø¨Ø± + Ø§Ù†ØªÙ‡Ø§ Ù„ÛŒÙ†Ú© Ú©Ø§Ù†Ø§Ù„ Ø¨Ø§ Ù…ÙˆØ¶ÙˆØ¹
                final_text = f"{content}\n\n@irfashionnews - Ù…Ø¯ Ùˆ ÙØ´Ù† Ø§ÛŒØ±Ø§Ù†ÛŒ\n\nğŸ”— {link}"

                try:
                    image_url = get_image_from_rss(entry)
                    if image_url:
                        await bot.send_photo(
                            chat_id=chat_id,
                            photo=image_url,
                            caption=final_text,
                            parse_mode='HTML',
                            disable_notification=True
                        )
                    else:
                        await bot.send_message(
                            chat_id=chat_id,
                            text=final_text,
                            link_preview_options=LinkPreviewOptions(is_disabled=True),
                            disable_notification=True
                        )

                    posted = True
                    print(f"[SUCCESS] Ù¾Ø³Øª Ù…ÙˆÙÙ‚ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {title[:60]}")

                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                    try:
                        databases.create_document(
                            database_id=database_id,
                            collection_id=collection_id,
                            document_id='unique()',
                            data={
                                'link': link,
                                'title': title,
                                'published_at': now.isoformat(),
                                'feed_url': feed_url,
                                'created_at': now.isoformat()
                            }
                        )
                        print("[SUCCESS] Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆÙÙ‚")
                    except Exception as save_err:
                        print(f"[WARN] Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {str(save_err)}")

                except Exception as send_err:
                    print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª: {str(send_err)}")

        except Exception as feed_err:
            print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙÛŒØ¯ {feed_url}: {str(feed_err)}")

    print(f"[INFO] Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ - Ù¾Ø³Øª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {posted}")
    return {"status": "success", "posted": posted}


async def translate_with_openrouter(client, prompt):
    try:
        response = await client.chat.completions.create(
            model="deepseek/deepseek-r1-0528:free",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
            max_tokens=900
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"[ERROR] Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ Ø¨Ø§ DeepSeek R1: {str(e)}")
        return "(ØªØ±Ø¬Ù…Ù‡ Ù…ÙˆÙ‚Øª - Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯)\n\nÙ„ÛŒÙ†Ú© Ø®Ø¨Ø± Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯."


def get_image_from_rss(entry):
    if 'enclosure' in entry and entry.enclosure.get('type', '').startswith('image/'):
        return entry.enclosure.href
    if 'media_content' in entry:
        for media in entry.media_content:
            if media.get('medium') == 'image' and media.get('url'):
                return media.get('url')
    return None


if __name__ == "__main__":
    asyncio.run(main())
